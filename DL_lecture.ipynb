{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCD6vKll9SMO"
      },
      "outputs": [],
      "source": [
        "# torch는 딥러닝을 구성하기 편하도록 META에서 만든 딥러닝 라이브러리, 텐서플로우랑 똑같은 딥러닝 라이브러리 # TMI=> torch 연구직에서 주로썼고, tensorflow 필드에서 주로썼었는데, 암튼 토치로 넘어오는 추세\n",
        "import torch\n",
        "\n",
        "# 신경망을 구축하기 쉽게 해주는 함수\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 확인  , gpu 가 없으면 cpu로 연산, gpu가 있으면 gpu로 연산하겠다는 준비, 따라서 device는 cpu나 gpu 문자열로 바뀐다.\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "id": "i540f9r4AJow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4명의 데이터가 있는데, 1명당 2개의 컬럼을 가지고 있다. 그리고 그걸 2차원 리스트로 4명의 데이터를 선언 후\n",
        "# 토치가 알아먹을 수 있는 Tensor 타입으로 바꾼다. (이때 tensor type은 float)\n",
        "# to(device)는 모델이 gpu에서 연산 될 것이기 때문에 to(cuda)를 함으로써 데이터를 gpu에 얹어 놓는다.\n",
        "\n",
        "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
        "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
      ],
      "metadata": {
        "id": "QtOJBG4hAKi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model == nn.Sequential( # 다른 라이브러리보다 유연한 설계가 가능, 다른 라이브러리는 비교적 간단해서 선호됨\n",
        "          nn.Linear(2, 10, bias=True), # input_layer = 2, hidden_layer1 = 10                  # 2개의 노드, 아웃풋은 10개\n",
        "          nn.Sigmoid(),\n",
        "          nn.Linear(10, 10, bias=True), # hidden_layer1 = 10, hidden_layer2 = 10                   \n",
        "          nn.Sigmoid(),\n",
        "          nn.Linear(10, 10, bias=True), # hidden_layer2 = 10, hidden_layer3 = 10\n",
        "          nn.Sigmoid(),\n",
        "          nn.Linear(10, 1, bias=True), # hidden_layer3 = 10, output_layer = 1\n",
        "          nn.Sigmoid()\n",
        "          ).to(device)"
      ],
      "metadata": {
        "id": "dD3d7AslALDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset # 텐서데이터셋\n",
        "from torch.utils.data import DataLoader # 데이터로더"
      ],
      "metadata": {
        "id": "doqInzCeHv4r"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 확인\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "VpBRfoQZHwbW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5명의 데이터, 각 데이터는 3개의 컬럼(피처)를 갖는다.\n",
        "x_train = torch.FloatTensor([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "# 정답값은 1사람당 1개\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
      ],
      "metadata": {
        "id": "uaGEsfSfHz0Z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X 데이터 셋과 Y 데이터 셋을 포장함\n",
        "dataset = TensorDataset(x_train, y_train)\n",
        "print(list(dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18jV3TYhIFls",
        "outputId": "a2a0a441-48e4-4d83-e530-79103fa5c13b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(tensor([73., 80., 75.]), tensor([152.])), (tensor([93., 88., 93.]), tensor([185.])), (tensor([89., 91., 90.]), tensor([180.])), (tensor([ 96.,  98., 100.]), tensor([196.])), (tensor([73., 66., 70.]), tensor([142.]))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2개 데이터를 1세트로 만들어서 전체 데이터 셋을 쪼갠다. 이때, 만든 n개의 세트들의 순서를 shuffle 한다.\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True) # shuffle => 개개개 고양이고양이 이런걸 셔플해서 섞어줌"
      ],
      "metadata": {
        "id": "-_NQMBmmJDb5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "          nn.Linear(3, 10, bias=True), # input_layer = 2, hidden_layer1 = 10\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(10, 10, bias=True), # hidden_layer1 = 10, hidden_layer2 = 10\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(10, 10, bias=True), # hidden_layer2 = 10, hidden_layer3 = 10\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(10, 1, bias=True), # hidden_layer3 = 10, output_layer = 1\n",
        "          nn.ReLU()\n",
        "          ).to(device)"
      ],
      "metadata": {
        "id": "hH6z4W4yKSr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.MSELoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5) # 0.00001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "c1wQ2lEpKtdc",
        "outputId": "c9cea58e-8342-4306-abdf-b993caa8cda8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-5dcd27c7153b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 0.00001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs = 5  # 전체학습때 5라면 ,미니배치때는 줄여봐야함\n",
        "for epoch in range(nb_epochs + 1): # 전체 데이터 셋으로 5번 학습할 것이다.\n",
        "  for batch_idx, samples in enumerate(dataloader): # minibatch 데이터를 반환하면서 index도 반환한다. (너무 초 대량의 데이터가 들어가면 GPU 터질까봐 minibatch를 한다)\n",
        "\n",
        "    x_train, y_train = samples \n",
        "\n",
        "    x_train= x_train.to(device)\n",
        "    y_train= y_train.to(y_train)\n",
        "\n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = criterion(prediction, y_train)\n",
        "\n",
        "    # cost로 H(x) 계산\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
        "        epoch, nb_epochs, batch_idx+1, len(dataloader),\n",
        "        cost.item()\n",
        "        ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "WKYRssGqKvls",
        "outputId": "9fbf4d48-8a1a-48b8-9265-4686a163cf4e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-79809b720a5e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# H(x) 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# cost 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fn04RrEAKwC3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}