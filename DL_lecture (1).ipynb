{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SCD6vKll9SMO"
      },
      "outputs": [],
      "source": [
        "# torch는 딥러닝을 구성하기 편하도록 META에서 만든 딥러닝 라이브러리, 텐서플로우랑 똑같은 딥러닝 라이브러리 # TMI=> torch 연구직에서 주로썼고, tensorflow 필드에서 주로썼었는데, 암튼 토치로 넘어오는 추세\n",
        "import torch\n",
        "\n",
        "# 신경망을 구축하기 쉽게 해주는 함수\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 확인  , gpu 가 없으면 cpu로 연산, gpu가 있으면 gpu로 연산하겠다는 준비, 따라서 device는 cpu나 gpu 문자열로 바뀐다.\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i540f9r4AJow",
        "outputId": "c53a3e8f-b29e-430d-cb8c-e6a8ec56b8e4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4명의 데이터가 있는데, 1명당 2개의 컬럼을 가지고 있다. 그리고 그걸 2차원 리스트로 4명의 데이터를 선언 후\n",
        "# 토치가 알아먹을 수 있는 Tensor 타입으로 바꾼다. (이때 tensor type은 float)\n",
        "# to(device)는 모델이 gpu에서 연산 될 것이기 때문에 to(cuda)를 함으로써 데이터를 gpu에 얹어 놓는다.\n",
        "\n",
        "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
        "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
      ],
      "metadata": {
        "id": "QtOJBG4hAKi0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential( # 다른 라이브러리보다 유연한 설계가 가능, 다른 라이브러리는 비교적 간단해서 선호됨\n",
        "          nn.Linear(2, 10, bias=True), # input_layer = 2, hidden_layer1 = 10                  # 2개의 노드, 아웃풋은 10개\n",
        "          nn.Sigmoid(),\n",
        "          nn.Linear(10, 10, bias=True), # hidden_layer1 = 10, hidden_layer2 = 10                   \n",
        "          nn.Sigmoid(),\n",
        "          nn.Linear(10, 10, bias=True), # hidden_layer2 = 10, hidden_layer3 = 10\n",
        "          nn.Sigmoid(),\n",
        "          nn.Linear(10, 1, bias=True), # hidden_layer3 = 10, output_layer = 1\n",
        "          nn.Sigmoid()\n",
        "          ).to(device)"
      ],
      "metadata": {
        "id": "dD3d7AslALDH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset # 텐서데이터셋\n",
        "from torch.utils.data import DataLoader # 데이터로더"
      ],
      "metadata": {
        "id": "doqInzCeHv4r"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 확인\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "VpBRfoQZHwbW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5명의 데이터, 각 데이터는 3개의 컬럼(피처)를 갖는다.\n",
        "x_train = torch.FloatTensor([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "# 정답값은 1사람당 1개\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
      ],
      "metadata": {
        "id": "uaGEsfSfHz0Z"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X 데이터 셋과 Y 데이터 셋을 포장함\n",
        "dataset = TensorDataset(x_train, y_train)\n",
        "print(list(dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18jV3TYhIFls",
        "outputId": "42be61cd-a126-4070-ac07-504df340bded"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(tensor([73., 80., 75.]), tensor([152.])), (tensor([93., 88., 93.]), tensor([185.])), (tensor([89., 91., 90.]), tensor([180.])), (tensor([ 96.,  98., 100.]), tensor([196.])), (tensor([73., 66., 70.]), tensor([142.]))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2개 데이터를 1세트로 만들어서 전체 데이터 셋을 쪼갠다. 이때, 만든 n개의 세트들의 순서를 shuffle 한다.\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True) # shuffle => 개개개 고양이고양이 이런걸 셔플해서 섞어줌"
      ],
      "metadata": {
        "id": "-_NQMBmmJDb5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "          nn.Linear(3, 10, bias=True), # input_layer = 2, hidden_layer1 = 10\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(10, 10, bias=True), # hidden_layer1 = 10, hidden_layer2 = 10\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(10, 10, bias=True), # hidden_layer2 = 10, hidden_layer3 = 10\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(10, 1, bias=True), # hidden_layer3 = 10, output_layer = 1\n",
        "          nn.ReLU()\n",
        "          ).to(device)"
      ],
      "metadata": {
        "id": "hH6z4W4yKSr6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.MSELoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5) # 0.00001"
      ],
      "metadata": {
        "id": "c1wQ2lEpKtdc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs = 5  # 전체학습때 5라면 ,미니배치때는 줄여봐야함\n",
        "for epoch in range(nb_epochs + 1): # 전체 데이터 셋으로 5번 학습할 것이다.\n",
        "  for batch_idx, samples in enumerate(dataloader): # minibatch 데이터를 반환하면서 index도 반환한다. (너무 초 대량의 데이터가 들어가면 GPU 터질까봐 minibatch를 한다)\n",
        "\n",
        "    x_train, y_train = samples \n",
        "\n",
        "    x_train= x_train.to(device)\n",
        "    y_train= y_train.to(y_train)\n",
        "\n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = criterion(prediction, y_train)\n",
        "\n",
        "    # cost로 H(x) 계산\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
        "        epoch, nb_epochs, batch_idx+1, len(dataloader),\n",
        "        cost.item()\n",
        "        ))"
      ],
      "metadata": {
        "id": "WKYRssGqKvls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.init"
      ],
      "metadata": {
        "id": "fn04RrEAKwC3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# 랜덤 시드 고정\n",
        "torch.manual_seed(777)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwaNHttbShOx",
        "outputId": "ebb809e2-f1b9-4e64-f149-d4228d470a66"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f0c6c651630>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "training_epochs = 15\n",
        "batch_size = 100"
      ],
      "metadata": {
        "id": "CCznXvl2SjGi"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train = dsets.MNIST(root='MNIST_data/', # 다운로드 경로 지정\n",
        "                          train=True, # True를 지정하면 훈련 데이터로 다운로드\n",
        "                          transform=transforms.ToTensor(), # 텐서로 변환\n",
        "                          download=True)\n",
        "\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/', # 다운로드 경로 지정\n",
        "                         train=False, # False를 지정하면 테스트 데이터로 다운로드\n",
        "                         transform=transforms.ToTensor(), # 텐서로 변환\n",
        "                         download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBD4T9vASmGj",
        "outputId": "1445447f-e503-427f-ec65-c0d089f1e7a5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 433970869.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 114171247.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 195817752.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 23260718.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          drop_last=True) # drop_last 마지막 남은 데이터를 버릴거냐 안버릴거냐"
      ],
      "metadata": {
        "id": "5xcZ0AtRSwDf"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.nn.Module:  PyTorch의 모든 Neural Network의 Base Class\n",
        "class CNN(torch.nn.Module): # 상속\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # 첫번째층\n",
        "        # ImgIn shape=(?, 28, 28, 1)\n",
        "        #    Conv     -> (?, 28, 28, 32)\n",
        "        #    Pool     -> (?, 14, 14, 32)\n",
        "        self.layer1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),   # Conv2d 채널을\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        # 두번째층\n",
        "        # ImgIn shape=(?, 14, 14, 32)\n",
        "        #    Conv      ->(?, 14, 14, 64)\n",
        "        #    Pool      ->(?, 7, 7, 64)\n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        # 전결합층 7x7x64 inputs -> 10 outputs\n",
        "        self.fc = torch.nn.Linear(7 * 7 * 64, 10, bias=True) # 1개의 데이터에 10개의 클래스 값\n",
        "\n",
        "        # 전결합층 한정으로 가중치 초기화\n",
        "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.view(out.size(0), -1)   # 전결합층을 위해서 Flatten\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "7XP-nWvaT-m8"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN 모델 정의\n",
        "model = CNN().to(device)"
      ],
      "metadata": {
        "id": "RC1yAN9LWwck"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss().to(device)    # 비용 함수에 소프트맥스 함수 포함되어져 있음. #CrossEntropyLoss 의 기능 soft max 부터 cross entropy까지 계산해줌\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "2ZIFy2_1WyGN"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_batch = len(data_loader)\n",
        "print('총 배치의 수 : {}'.format(total_batch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aD-ogLiYG15",
        "outputId": "a934153d-74fa-4b95-c45c-2f4dbc66fcec"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 배치의 수 : 600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "\n",
        "    for X, Y in data_loader: # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y는 레이블.\n",
        "        # image is already size of (28x28), no reshape\n",
        "\n",
        "        X = X.to(device)\n",
        "        Y = Y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        hypothesis = model(X)\n",
        "        cost = criterion(hypothesis, Y)\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_cost += cost / total_batch\n",
        "\n",
        "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GI1eN1l5X2JL",
        "outputId": "9214b102-c075-4215-e5b8-63b9392234d6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch:    1] cost = 0.225595474\n",
            "[Epoch:    2] cost = 0.0629839227\n",
            "[Epoch:    3] cost = 0.0463118628\n",
            "[Epoch:    4] cost = 0.037405543\n",
            "[Epoch:    5] cost = 0.0314706899\n",
            "[Epoch:    6] cost = 0.0260603409\n",
            "[Epoch:    7] cost = 0.0218301043\n",
            "[Epoch:    8] cost = 0.0180830602\n",
            "[Epoch:    9] cost = 0.0162577052\n",
            "[Epoch:   10] cost = 0.0129458187\n",
            "[Epoch:   11] cost = 0.00997531693\n",
            "[Epoch:   12] cost = 0.0103649357\n",
            "[Epoch:   13] cost = 0.00820257701\n",
            "[Epoch:   14] cost = 0.0065609361\n",
            "[Epoch:   15] cost = 0.00653103925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습을 진행하지 않을 것이므로 torch.no_grad(), gradient descent를 하지마라고 명령내리는 것\n",
        "with torch.no_grad():\n",
        "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
        "    Y_test = mnist_test.test_labels.to(device)\n",
        "\n",
        "    prediction = model(X_test)\n",
        "                        # CNN은 10개의 아웃풋으로 각 10개의 클래스에 대한 피처값이 나온다, 이를 axis 1방향으로 max값을 찾는다는 것\n",
        "                        # 이를 axis 1방향으로 max값을 찾는다는 것\n",
        "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
        "                        # torch.argmax(prediction, 1)는 피쳐값중 max인 인덱스 (=label)을 뽑는것\n",
        "   #accuracy = correct_prediction.float().mean()\n",
        "   #print('Accuracy:', accuracy.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDPAxrn2YDF_",
        "outputId": "8ed7d166-1db8-4eee-c4bf-7f258caac208"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/datasets/mnist.py:80: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/datasets/mnist.py:70: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 저장 \n",
        "torch.save(model.state_dict(),\"cnn_model.pt\")"
      ],
      "metadata": {
        "id": "ZrlkwEIKaElh"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습을 진행하지 않을 것이므로 torch.no_grad(), gradient descent를 하지마라고 명령내리는 것\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    # 이미지 파일 경로 설정\n",
        "    img = Image.open(\"./8.png\")\n",
        "    transform = transforms.Compose([\n",
        "          transforms.Grayscale(num_output_channels=1), # RGB(3D) -> Gray(2D)\n",
        "          transforms.Resize((28, 28)), # 모델 인풋에 맞게\n",
        "          transforms.ToTensor(), # 토치 텐서 타입으로 맞춰줘야함\n",
        "      ])\n",
        "    \n",
        "    img_tensor = transform(img).to(device) # [1, 28, 28]\n",
        "    img_tensor = img_tensor.unsqueeze(0) # [1, 1, 28, 28] #모델이 원래 [배치사이즈 가로 세로 등]\n",
        "\n",
        "    print(img_tensor.shape)\n",
        "\n",
        "    prediction = model(img_tensor)\n",
        "                        # CNN은 10개의 아웃풋으로 각 10개의 클래스에 대한 피처값이 나온다, 이를 axis 1방향으로 max값을 찾는다는 것 \n",
        "    print('result:', torch.argmax(prediction, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYAQsqo6aHmD",
        "outputId": "9265626c-870b-4073-b811-f7e9b8013bc2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 28, 28])\n",
            "result: tensor([8], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8l7MBnoGuQ7y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}